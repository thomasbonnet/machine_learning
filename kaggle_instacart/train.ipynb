{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_userXproduct = pd.read_csv('data/userXproduct_train.csv',index_col=['user_id','product_id'],#nrows=10000,\n",
    "                             dtype={'user_id':np.uint32,\n",
    "                                    'product_id':np.uint32,\n",
    "                                    'mean_atco':np.float32,\n",
    "                                    'mean_order_how':np.float32,\n",
    "                                    'number_reord':np.uint8,\n",
    "                                    'dblo':np.float32,\n",
    "                                    'dslo':np.uint8,\n",
    "                                    'mean_order_hod':np.float32,\n",
    "                                    'mean_order_dow':np.float32,\n",
    "                                    'reord_per_aisle':np.uint32,\n",
    "                                    'ord_per_aisle':np.uint32,\n",
    "                                    'reord_per_depart':np.uint32,\n",
    "                                    'ord_per_depart':np.uint32,\n",
    "                                    'train_order_number':np.uint8,\n",
    "                                    'train_dspo':np.float16,\n",
    "                                    'reord_per_user':np.uint16,\n",
    "                                    'reord_per_dow':np.uint32,\n",
    "                                    'ord_per_dow':np.uint32, \n",
    "                                    'reord_per_hod':np.uint32,\n",
    "                                    'ord_per_hod':np.uint32,\n",
    "                                    'reord_per_how':np.uint32,\n",
    "                                    'ord_per_how':np.uint32\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'mean_atco', u'mean_order_hod', u'mean_order_how', u'number_reord',\n",
       "       u'dslo', u'mean_order_dow', u'dblo', u'reord_per_aisle',\n",
       "       u'ord_per_aisle', u'reord_per_depart', u'ord_per_depart',\n",
       "       u'train_order_number', u'train_dspo', u'order_dow', u'reord_per_dow',\n",
       "       u'ord_per_dow', u'order_hod', u'reord_per_hod', u'ord_per_hod',\n",
       "       u'order_how', u'reord_per_how', u'ord_per_how'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userXproduct.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_target  = pd.read_csv('data/target_train.csv',index_col=['user_id','product_id'])\n",
    "df_userXproduct = df_userXproduct.join(df_target)\n",
    "df_userXproduct.fillna(False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_userXproduct['reordered_ratio'] = df_userXproduct['number_reord'] /(df_userXproduct['train_order_number']-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean_atco', 'mean_order_hod', 'mean_order_how', 'number_reord',\n",
       "       'dslo', 'mean_order_dow', 'dblo', 'reord_per_aisle',\n",
       "       'ord_per_aisle', 'reord_per_depart', 'ord_per_depart',\n",
       "       'train_order_number', 'train_dspo', 'order_dow', 'reord_per_dow',\n",
       "       'ord_per_dow', 'order_hod', 'reord_per_hod', 'ord_per_hod',\n",
       "       'order_how', 'reord_per_how', 'ord_per_how', 'reordered',\n",
       "       'reordered_ratio'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userXproduct.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df_userXproduct.reset_index()[['user_id',\n",
    "                                   'product_id',\n",
    "                                   'mean_atco', \n",
    "                                   'mean_order_hod',\n",
    "                                   'mean_order_how', \n",
    "                                   'number_reord',\n",
    "                                   'dslo', \n",
    "                                   'mean_order_dow',\n",
    "                                   'dblo', \n",
    "                                   'reord_per_aisle',\n",
    "                                   'ord_per_aisle', \n",
    "                                   'reord_per_depart', \n",
    "                                   'ord_per_depart',\n",
    "                                   'train_order_number',\n",
    "                                   'train_dspo',\n",
    "                                   'order_dow', \n",
    "                                   'reord_per_dow',\n",
    "                                   'ord_per_dow', \n",
    "                                   'order_hod',\n",
    "                                   'reord_per_hod',\n",
    "                                   'ord_per_hod',\n",
    "                                   'order_how', \n",
    "                                   'reord_per_how',\n",
    "                                   'ord_per_how', \n",
    "                                   'reordered',\n",
    "                                   'reordered_ratio'\n",
    "                                    ]].values\n",
    "\n",
    "y = df_userXproduct.reset_index()[['user_id','product_id','reordered']].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cols = [                           'mean_atco', \n",
    "#                                   'mean_order_how', \n",
    "#                                   #'number_reord', \n",
    "#                                   #'mean_order_dow', \n",
    "#                                   'reord_per_aisle', \n",
    "#                                   'reord_per_depart',\n",
    "#                                   #'train_order_number', \n",
    "#                                   'train_dspo', \n",
    "#                                   'reord_per_user',\n",
    "#                                   #'reord_per_dow', \n",
    "#                                   #'reord_per_hod', \n",
    "#                                   'reord_per_how', \n",
    "#                                   'reordered_ratio'\n",
    "#                                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#g = sns.pairplot(df_userXproduct.loc[:10,cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:,2:] = scale(X[:,2:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "groups_user_ids = X[:,0]\n",
    "group_kfold = GroupKFold(n_splits=4)\n",
    "ind_train, ind_test = next(group_kfold.split(X, y, groups_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.6,random_state=42)\n",
    "X_train = X[ind_train]\n",
    "y_train = y[ind_train]\n",
    "X_test  = X[ind_test]\n",
    "y_test  = y[ind_test]\n",
    "\n",
    "print (X_train.shape,y_train.shape)\n",
    "print (X_test.shape,y_test.shape)\n",
    "print (float(len(X_test))/(len(X_test)+len(X_train)))\n",
    "\n",
    "y_train = np.append(y_train,to_categorical(y_train[:,2]),axis=1)\n",
    "#y_test = np.append(y_test,to_categorical(y_test[:,2]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds_pos = np.argwhere(y_train[:,2]==True).reshape(-1)\n",
    "inds_neg = np.argwhere(y_train[:,2]==False).reshape(-1)\n",
    "\n",
    "print(float(len(inds_pos))/(len(inds_pos)+len(inds_neg)))\n",
    "inds_neg = np.random.choice(inds_neg,size=len(inds_pos))\n",
    "inds = np.random.permutation(np.append(inds_pos,inds_neg))\n",
    "\n",
    "print(float(len(inds_pos))/(len(inds)))\n",
    "\n",
    "X_train = X_train[inds]\n",
    "y_train = y_train[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model_keras():\n",
    "    # create the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = (X_train.shape[1]-2,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])      \n",
    "    \n",
    "    print(model.summary())\n",
    "    early_stopping_monitor = EarlyStopping(patience=2)\n",
    "    model.fit(X_train[:,2:], y_train[:,[3,4]], epochs=20, batch_size=64,validation_split=0.3,callbacks = [early_stopping_monitor])\n",
    "\n",
    "\n",
    "    from keras.models import load_model\n",
    "    model.save('model_file2.h5')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_model_sklearn():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    #y_train[:,4].reshape(-1).astype(int)\n",
    "    y_prepro = y_train[:,4].reshape(-1).astype(np.int)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    #classifier = SVC(kernel=\"linear\", C=0.025)\n",
    "    #classifier = KNeighborsClassifier(3)\n",
    "    classifier.fit(X_train[:,2:], y_prepro[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "def fit_model_xgb():\n",
    "    \n",
    "    # specify parameters via map\n",
    "    num_round = 20\n",
    "    \n",
    "    xgb_params = {\n",
    "        #'n_trees': 50, \n",
    "        'eta': 0.1,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.76,\n",
    "        'objective': 'binary:logistic', #'reg:logistic',#'binary:logistic'\n",
    "        'eval_metric': ['logloss','auc'],\n",
    "        'lambda': 10,\n",
    "        'gamma': .7,\n",
    "        'colsample_bytree':.95,\n",
    "        'silent': 0,\n",
    "        'alpha': 2e-05\n",
    "    }\n",
    "\n",
    "    \n",
    "    y_prepro = y_train[:,4].reshape(-1).astype(np.int)\n",
    "    dtrain = xgb.DMatrix(X_train[:,2:],label=y_prepro)\n",
    "   \n",
    "    \n",
    "    return xgb.train(xgb_params, dtrain, num_round,verbose_eval=True)\n",
    "    # make prediction\n",
    "    \n",
    "\n",
    "bst = fit_model_xgb()\n",
    "\n",
    "dtest  = xgb.DMatrix(X_test[:,2:])\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "bst.save_model('model_xgb.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_resultats = pd.DataFrame(y_test,columns=['user_id','product_id','test'])\n",
    "df_resultats['pred_false'] = 0. \n",
    "df_resultats['pred_true'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "         n_estimators=1000,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0,\n",
    "         subsample=0.8,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                   min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                   objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle.dump(bst, open(\"model_xgb.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "y_prepro = y_train[:,4].reshape(-1).astype(np.int)\n",
    "\n",
    "#gbm = xgb.XGBClassifier(max_depth=3,\n",
    "#                        n_estimators=300,\n",
    "#                        learning_rate=0.05).fit(X_train[:,2:],y_prepro)\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=6,\n",
    "                        #n_estimators=300,\n",
    "                        subsample=0.76,\n",
    "                        objective='reg:logistic',\n",
    "                        reg_lambda=10,\n",
    "                        reg_alpha=2e-05,\n",
    "                        gamma=.7,\n",
    "                        colsample_bytree=.95,\n",
    "                        silent=1,\n",
    "                        learning_rate=0.1).fit(X_train[:,2:],y_prepro)\n",
    "\n",
    "predictions = gbm.predict(X_test[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle.dump(gbm, open(\"model_xgb.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = gbm.predict_proba(X_test[:,2:])\n",
    "y_pred = np.append(y_test,y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = 'keras'\n",
    "    \n",
    "if mod == 'keras':\n",
    "    fit_model_keras()\n",
    "    from keras.models import load_model\n",
    "    model = load_model('model_file2.h5')\n",
    "\n",
    "    y_pred = np.append(y_test,model.predict(X_test[:,2:]),axis=1)\n",
    "    \n",
    "else:\n",
    "    fit_model_sklearn()\n",
    "    \n",
    "    y_pred = classifier.predict_proba(X_test[:,2:])\n",
    "    y_pred = np.append(y_test,y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_resultats = pd.DataFrame(y_pred,columns=['user_id','product_id','test','pred_false','pred_true'])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_resultats = df_resultats.set_index(['user_id','product_id'])\n",
    "df_resultats['test'] = df_resultats['test'].astype(np.bool)\n",
    "#df_resultats['pred_false'] = df_resultats['pred_false'].astype(np.float32)\n",
    "df_resultats['pred_true'] = df_resultats['pred_true'].astype(np.float32)\n",
    "del df_resultats['pred_false']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(df_resultats.test, df_resultats.pred_true>0.5))\n",
    "print(classification_report(df_resultats.test, df_resultats.pred_true>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_resultats.test, df_resultats.pred_true)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_score = roc_auc_score(df_resultats.test, df_resultats.pred_true)\n",
    "print (roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('Reading the orders dataset...')\n",
    "df_orders = pd.read_csv('data/orders.csv',dtype={'order_id':np.uint32,\n",
    "                                                 'user_id':np.uint32,\n",
    "                                                 'order_number':np.uint8,\n",
    "                                                 'order_dow':np.uint8,\n",
    "                                                 'order_hour_of_day':np.uint8,\n",
    "                                                 'days_since_prior_order':np.float16})\n",
    "\n",
    "df_orders_test = df_orders.loc[df_orders['eval_set']=='train']\n",
    "\n",
    "print('Reading the train products dataset...')\n",
    "df_products_train = pd.read_csv('data/order_products__train.csv',dtype={'order_id':np.uint32,\n",
    "                                                                        'product_id':np.uint32,\n",
    "                                                                        'add_to_cart_order':np.uint8,\n",
    "                                                                        'reordered':np.bool})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_resultats_true = df_resultats.loc[df_resultats.test==True,'test'].reset_index()\n",
    "df_resultats_true = df_resultats_true.groupby(['user_id'])['product_id'].apply(lambda x : ' '.join(x.astype(str)))\n",
    "df_resultats_true = df_resultats_true.rename('product_id_true')\n",
    "\n",
    "user_id_to_predict = df_resultats.reset_index().user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_pred(df_resultats,decision_threshold):\n",
    "\n",
    "    #decision_threshold = 0.3\n",
    "    df_resultats_pred = df_resultats.loc[df_resultats.pred_true>decision_threshold].reset_index()\n",
    "    df_resultats_pred['pred_true'] = True\n",
    "    df_resultats_pred = df_resultats_pred.groupby(['user_id'])['product_id'].apply(lambda x : ' '.join(x.astype(str)))\n",
    "    df_resultats_pred = df_resultats_pred.rename('product_id')\n",
    "\n",
    "    df_resultats_final = pd.concat([df_resultats_true,df_resultats_pred],axis=1)\n",
    "\n",
    "    df_resultats_final = df_resultats_final.reindex(user_id_to_predict)\n",
    "    df_resultats_final = df_resultats_final.fillna('None')\n",
    "\n",
    "    df_resultats_final = df_orders_test.join(df_resultats_final,on='user_id',how='right')[['order_id',\n",
    "                                                                                         'product_id_true',\n",
    "                                                                                         'product_id']].sort_values('order_id') \n",
    "    \n",
    "    df_resultats_final['f1'] = df_resultats_final.apply(f1_score_perso,axis=1)    \n",
    "    return decision_threshold,np.mean(df_resultats_final['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from wikipedia : https://en.wikipedia.org/wiki/F1_score\n",
    "# f1 = 2 * precision * recall / (precision+recall)\n",
    "# precision  = number of true posisive  / number of predicted positive\n",
    "# recall     = number of true posisive  / number of positives\n",
    "\n",
    "def f1_score_perso(row):\n",
    "    y_pred = row['product_id']\n",
    "    y_true = row['product_id_true']\n",
    "    if y_pred == 'None':\n",
    "        y_pred = [0]\n",
    "    else:\n",
    "        y_pred = [int(y) for y in y_pred.split(' ')]\n",
    "    if y_true == 'None':\n",
    "        y_true = [0]\n",
    "    else:\n",
    "        y_true = [int(y) for y in y_true.split(' ')]\n",
    "    true_pos = np.intersect1d(y_pred,y_true)\n",
    "    precision = len(true_pos) / float(len(y_pred))\n",
    "    recall = len(true_pos) / float(len(y_true))\n",
    "    if precision+recall == 0:\n",
    "        f1 = 0.\n",
    "    else :\n",
    "        f1 = 2 * precision * recall / (precision+recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#decision_thresholds = np.arange(0.1,0.95,0.1)\n",
    "decision_thresholds = np.arange(0.4,0.76,0.01)\n",
    "#decision_thresholds = np.array([0.5])\n",
    "#decision_thresholds = np.arange(0.05,0.26,0.01)\n",
    "#decision_thresholds = np.arange(0.6,1.,0.05)\n",
    "#decision_thresholds = []\n",
    "f1_sco = []\n",
    "\n",
    "for decision_threshold in decision_thresholds:\n",
    "    var_tmp = test_pred(df_resultats, decision_threshold)\n",
    "    f1_sco.append(var_tmp[1])\n",
    "    print (var_tmp)\n",
    "\n",
    "    \n",
    "ind_best = np.argmax(f1_sco)\n",
    "print('=======================================================================')\n",
    "print ('auroc:',roc_score, ',th:',decision_thresholds[ind_best],',f1:', f1_sco[ind_best])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
